{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef05e0a3",
   "metadata": {},
   "source": [
    "# **Fashion MNIST with Keras [Theano Backend]**\n",
    "\n",
    "## **Overview**\n",
    "Fashion MNIST is a dataset that resembles MNIST but instead of handwritten digits, itÂ uses images of clothing. There are 10 classes and each image is 28x28 grayscale. A total of 70000 images; 60000 for training and 10,000 for testing make up the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65065a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Toggling between CPU and GPU\n",
    "# GPU in use is NVIDIA GEFORCE 940M\n",
    "# Theano backend is being used for keras\n",
    "# To make the GPU unavailable, uncomment the line of code below\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8101688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "file_name = 'my_save_model'\n",
    "tensorboard = TensorBoard(log_dir=\"logs\\\\{}\".format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a745dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "#from time import time\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys,humanize,psutil,GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb0a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (validation_images, validation_labels) = fashion_mnist.load_data()\n",
    "print(\"Training dataset\")\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print('Validation dataset:')\n",
    "print(validation_images.shape)\n",
    "print(validation_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets determine the dataset characteristics\n",
    "print('Training Images: {}'.format(train_images.shape))\n",
    "print('Testing Images: {}'.format(validation_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a70627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for a single image \n",
    "print(train_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(train_images[2], cmap = 'gray')\n",
    "plt.show()\n",
    "print(train_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19f06b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a convolutional neural network for object recognition on Fashion MNIST data.\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 6\n",
    "np.random.seed(seed) \n",
    "\n",
    "# load the data\n",
    "(train_images, train_labels), (validation_images, validation_labels) = fashion_mnist.load_data()\n",
    "\n",
    "rows, cols = 28, 28\n",
    "train_images = train_images.reshape(train_images.shape[0], 1, 28, 28)\n",
    "validation_images = validation_images.reshape(validation_images.shape[0], 1, 28, 28)\n",
    "\n",
    "input_shape = (1, rows, cols)\n",
    "\n",
    "# normalize the inputs from 0-255 to 0.0-1.0\n",
    "train_images = train_images.astype('float32')\n",
    "validation_images = validation_images.astype('float32')\n",
    "train_images = train_images / 255.0\n",
    "validation_images = validation_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419be757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class labels shape\n",
    "print(train_labels.shape)\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82631c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hot encode outputs\n",
    "train_labels = np_utils.to_categorical(train_labels)\n",
    "validation_labels = np_utils.to_categorical(validation_labels)\n",
    "num_classes = validation_labels.shape[1]\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255cda3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Buiding\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "# Convolution 1: Filters as we know is 6. Filter size is 5x5, relu is the activation function\n",
    "model.add(Conv2D(filters = 6, kernel_size = 5, strides = 1, activation = 'relu', input_shape=input_shape))\n",
    "# Pooling Layer 1\n",
    "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "\n",
    "# Layer 2\n",
    "# Convolution 2: Input = 14x14x6. Output = 10x10x16 Conv2d\n",
    "model.add(Conv2D(filters = 16, kernel_size = 5, strides = 1, activation = 'relu', input_shape=(6,14,14)))\n",
    "# Pooling Layer 2\n",
    "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "\n",
    "# Flatten \n",
    "model.add(Flatten())\n",
    "\n",
    "# Layer 3\n",
    "# Fully Connected Layer 1\n",
    "model.add(Dense(units= 120, activation = 'relu'))\n",
    "\n",
    "# Layer 4\n",
    "# Fully Connected Layer 2\n",
    "model.add(Dense(units= 84, activation = 'relu'))\n",
    "\n",
    "# Layer 5\n",
    "# Output Laer\n",
    "model.add(Dense(units= 10, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.optimizers import SGD\n",
    "# define hyper parameters\n",
    "learning_rate = 0.01\n",
    "weight_decay = 1e-6\n",
    "momentum = 0.9\n",
    "\n",
    "t1 = time.time()\n",
    "# define optimizer and compile model\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b824b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function (For CPU) Memory Report\n",
    "def cpu_mem_report():\n",
    "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
    "\n",
    "  # Getting usage of cpu virtual_memory in GB\n",
    "  print('RAM Used (GB):', psutil.virtual_memory()[3]/1000000000)\n",
    "  # Getting % usage of cpu virtual_memory\n",
    "  print('CPU RAM % used: ', psutil.virtual_memory()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ea730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function (For GPU) Memory Report\n",
    "def gpu_mem_report():\n",
    "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
    "\n",
    "  GPUs = GPUtil.getGPUs()\n",
    "  for i, gpu in enumerate(GPUs):\n",
    "    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0a6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "t1 = time.time()\n",
    "\n",
    "# Training for 10 epochs and a batch size of 10\n",
    "history = model.fit( train_images, train_labels, verbose=1, epochs = 10, batch_size = 10, validation_split = 0.2, callbacks=[tensorboard])\n",
    "#model.fit(train_images[:20000], train_labels[:20000], epochs = , batch_size = 10)\n",
    "t2 = time.time() \n",
    "print(\"Training Time: \", t2-t1)\n",
    "cpu_mem_report()\n",
    "#gpu_mem_report()\n",
    "#print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40950d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the framework on the Test dataset\n",
    "t1 = time.time()\n",
    "\n",
    "#test_loss, test_acc = model.evaluate(validation_images, validation_labels, verbose=2)\n",
    "#print(\"Testing Loss: \", test_loss)\n",
    "#print(\"Testing Accuracy: \", test_acc*100,\"%\")\n",
    "\n",
    "_, acc = model.evaluate(validation_images, validation_labels)\n",
    "print(\"Accuracy = \", (acc*100.0), \"%\")\n",
    "\n",
    "t2 = time.time() \n",
    "print(\"Testing Time: \", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40888998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training Loss')\n",
    "plt.plot(epochs, val_loss,'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc,'r', label='Validation acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715f8e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyTestEnv",
   "language": "python",
   "name": "mytestenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
