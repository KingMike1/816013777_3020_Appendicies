{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51bb3e51-70c2-437d-971a-11ce3955f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Toggling between CPU and GPU\n",
    "# GPU in use is NVIDIA GEFORCE 940M\n",
    "# To make the GPU unavailable, uncomment the line of code below\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0981a34-bf13-4b2a-96b9-d47913a8fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in relevant libraries, and alias where appropriate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import time\n",
    "import sys,humanize,psutil,GPUtil\n",
    "\n",
    "# Define relevant variables for the ML task\n",
    "batch_size = 10\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d30f728-6776-49e7-b13c-9b58635200ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27aa1a79-b0f2-45e3-aa99-8f6fdc74e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#default log_dir is runs\n",
    "writer = SummaryWriter('runs/MNIST_Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd7fc8d9-156e-4246-8cf7-a51288e3fe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea9e44f2e024ac2b92a89496ee73f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d85c8cd22a248a6856162232b9f0dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca8c33087a542f2a23c84b69aea4d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04812ab5718b4f70930af7d530473775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading the dataset and preprocessing\n",
    "train_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                           train = True,\n",
    "                                           transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n",
    "                                           download = True)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                          train = False,\n",
    "                                          transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n",
    "                                          download=True)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "799d1ad8-ab23-4ee0-9ae5-75e0d46dcd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the convolutional neural network\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e8be7ac-4030-4a92-953b-c7a96cb4bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5(num_classes).to(device)\n",
    "\n",
    "#Setting the loss function\n",
    "cost = nn.CrossEntropyLoss()\n",
    "\n",
    "#Setting the optimizer with the model parameters and learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#this is defined to print how many steps are remaining when training\n",
    "total_step = len(train_loader)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88346be3-6905-49fc-b41d-910b828a6948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function (For CPU) Memory Report\n",
    "def cpu_mem_report():\n",
    "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
    "\n",
    "  # Getting usage of cpu virtual_memory in GB\n",
    "  print('RAM Used (GB):', psutil.virtual_memory()[3]/1000000000)\n",
    "  # Getting % usage of cpu virtual_memory\n",
    "  print('CPU RAM % used: ', psutil.virtual_memory()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ef99271-f87d-4ead-bf46-741df18471fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function (For GPU) Memory Report\n",
    "def gpu_mem_report():\n",
    "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
    "\n",
    "  GPUs = GPUtil.getGPUs()\n",
    "  for i, gpu in enumerate(GPUs):\n",
    "    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5f4e0c6-65ba-4f2b-9f0a-9d595eed8b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Finished Training\n",
      "Training Time:  877.1922941207886\n",
      "CPU RAM Free: 3.8 GB\n",
      "RAM Used (GB): 4.70355968\n",
      "CPU RAM % used:  55.3\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "t1 = time.time()\n",
    "for epoch in range(num_epochs): # loop over the dataset multiple times\n",
    "    total_train_loss = 0.0\n",
    "    total_test_loss = 0.0\n",
    "\n",
    "    print (\"Epoch: \", epoch)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    total = 0\n",
    "    for idx, (image, label) in enumerate(train_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(image)\n",
    "\n",
    "        loss = cost(pred, label)\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        pred = torch.nn.functional.softmax(pred, dim=1)\n",
    "\n",
    "        for i, p in enumerate(pred):\n",
    "\n",
    "            if label[i] == torch.max(p.data, 0)[1]:\n",
    "                total = total + 1\n",
    "  \n",
    "    total_train_acc = total / len(train_dataset)\n",
    "    total_train_loss = total_train_loss / (idx + 1)\n",
    "\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for idx, (image, label) in enumerate(test_loader):\n",
    "       image, label = image.to(device), label.to(device)\n",
    "\n",
    "       pred = model(image)\n",
    "       loss = cost(pred, label)\n",
    "       total_test_loss += loss.item()\n",
    "       pred = torch.nn.functional.softmax(pred, dim=1)\n",
    "       for i, p in enumerate(pred):\n",
    "          if label[i] == torch.max(p.data, 0)[1]:\n",
    "              total = total + 1\n",
    "\n",
    "    total_test_acc = total / len(test_dataset)\n",
    "    total_test_loss = total_test_loss / (idx + 1)\n",
    "\n",
    "    if epoch %2 == 0: # every 2'nd epoch\n",
    "    \n",
    "        writer.add_scalars('Loss',\n",
    "                           {'Training': total_train_loss,\n",
    "                            'Testing': total_test_loss},\n",
    "                            epoch)\n",
    "      \n",
    "        writer.add_scalars('Accuracy',\n",
    "                          {'Training': total_train_acc,\n",
    "                           'Testing': total_test_acc},\n",
    "                           epoch)\n",
    "        writer.close()\n",
    "        print(\"Epoch: \", epoch)\n",
    "\n",
    "    total_train_loss = 0.0\n",
    "    total_test_loss = 0.0\n",
    "\n",
    "  \n",
    "t2 = time.time() \n",
    "print('Finished Training')\n",
    "print(\"Training Time: \", t2-t1)\n",
    "cpu_mem_report()\n",
    "#gpu_mem_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "621951b5-d7da-48a8-a3e1-23ef22295c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.94 %\n",
      "Testing Time:  7.207873344421387\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "t1 = time.time()  \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "    \n",
    "t2 = time.time() \n",
    "print(\"Testing Time: \", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7448b2-0575-4c2d-8f34-5126c204fe37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinalYearCodes",
   "language": "python",
   "name": "finalyearcodes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
