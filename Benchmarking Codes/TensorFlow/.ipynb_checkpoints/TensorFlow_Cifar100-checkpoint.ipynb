{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fcfbf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Toggling between CPU and GPU\n",
    "# GPU in use is NVIDIA GEFORCE 940M\n",
    "# Theano backend is being used for keras\n",
    "# To make the GPU unavailable, uncomment the line of code below\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ae45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "file_name = 'my_save_model'\n",
    "tensorboard = TensorBoard(log_dir=\"logs\\\\{}\".format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af6f5cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import datetime, os\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import sys,humanize,psutil,GPUtil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ff5c53",
   "metadata": {},
   "source": [
    "# Loading the CIFAR-100 dataset (CIFAR stands for Canadian Institute For Advanced Research)\n",
    "\n",
    "## CIFAR-100 Dataset:\n",
    "Similar to the CIFAR-10, this dataset comprises 100 classes with a total of 600 images. For each class, there are 500 training photos and 100 test images. The CIFAR-100's 100 classes are divided into 20 super classes. Each image has a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs).\n",
    "\n",
    "The list of classes in the CIFAR-10 dataset are listed below:\n",
    "\n",
    "![title](CIFAR100.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ecde88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dataset (CIFAR-10 dataset)\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar100.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "977abcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 36)        2736      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 16)        14416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               8500      \n",
      "=================================================================\n",
      "Total params: 83,936\n",
      "Trainable params: 83,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Buiding\n",
    "LeNet = models.Sequential()\n",
    "\n",
    "# Convolution 1: Filters as we know is 6. Filter size is 5x5, relu is the activation function\n",
    "LeNet.add(layers.Conv2D(36, (5,5), activation = 'relu', input_shape=(32,32,3)))\n",
    "# Subsampling 1: Input  = 32x32x6. Output = 14x14x6. SubSampling is simply MaxPooling so we use MaxPool (image reduction factor of 2)\n",
    "LeNet.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# Convolution 2: Input = 14x14x6. Output = 10x10x16 Conv2d\n",
    "LeNet.add(layers.Conv2D(16, (5,5), activation='relu'))\n",
    "# Subsampling 2: Input 32x32x6. Output = 14x14x6. SubSampling is simply MaxPooling so we use MaxPool (image reduction factor of 2)\n",
    "LeNet.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# Flatten for further steps to happen\n",
    "# It is the process of converting all the resultant 2D arrays as single long continous linear vector\n",
    "LeNet.add(layers.Flatten())\n",
    "\n",
    "# Fully connected 1: Input = 5x5x16. Output = 120\n",
    "LeNet.add(layers.Dense(120, activation='relu'))\n",
    "\n",
    "# Fully connected 2: Input =120. Output = 84\n",
    "LeNet.add(layers.Dense(84, activation='relu'))\n",
    "\n",
    "# Final, Output and activation through softmax\n",
    "LeNet.add(layers.Dense(100, activation='softmax'))\n",
    "LeNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c16aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "LeNet.compile(optimizer = 'Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00ea2edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function (For CPU) Memory Report\n",
    "def cpu_mem_report():\n",
    "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
    "\n",
    "  # Getting usage of cpu virtual_memory in GB\n",
    "  print('RAM Used (GB):', psutil.virtual_memory()[3]/1000000000)\n",
    "  # Getting % usage of cpu virtual_memory\n",
    "  print('CPU RAM % used: ', psutil.virtual_memory()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36027e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function (For GPU) Memory Report\n",
    "def gpu_mem_report():\n",
    "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
    "\n",
    "  GPUs = GPUtil.getGPUs()\n",
    "  for i, gpu in enumerate(GPUs):\n",
    "    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bea22499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 125s 3ms/step - loss: 4.6064 - acc: 0.0095 - val_loss: 4.6069 - val_acc: 0.0084\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 126s 3ms/step - loss: 4.6062 - acc: 0.0096 - val_loss: 4.6078 - val_acc: 0.0084\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 125s 3ms/step - loss: 4.6062 - acc: 0.0094 - val_loss: 4.6079 - val_acc: 0.0084\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 126s 3ms/step - loss: 4.6062 - acc: 0.0096 - val_loss: 4.6082 - val_acc: 0.0077\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 124s 3ms/step - loss: 4.6062 - acc: 0.0098 - val_loss: 4.6082 - val_acc: 0.0087\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 128s 3ms/step - loss: 4.6062 - acc: 0.0097 - val_loss: 4.6080 - val_acc: 0.0087\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 126s 3ms/step - loss: 4.6062 - acc: 0.0093 - val_loss: 4.6081 - val_acc: 0.0077\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 126s 3ms/step - loss: 4.6062 - acc: 0.0090 - val_loss: 4.6080 - val_acc: 0.0085\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 127s 3ms/step - loss: 4.6062 - acc: 0.0096 - val_loss: 4.6081 - val_acc: 0.0085\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 128s 3ms/step - loss: 4.6062 - acc: 0.0102 - val_loss: 4.6080 - val_acc: 0.0085\n",
      "Training Time:  1265.783128976822\n",
      "CPU RAM Free: 2.2 GB\n",
      "RAM Used (GB): 6.341722112\n",
      "CPU RAM % used:  74.6\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "t1 = time.time()\n",
    "\n",
    "# Training for 10 epochs and a batch size of 10\n",
    "history = LeNet.fit( train_images, train_labels, verbose=1, epochs = 10, batch_size = 10, validation_split = 0.2, callbacks=[tensorboard])\n",
    "#model.fit(train_images[:20000], train_labels[:20000], epochs = , batch_size = 10)\n",
    "t2 = time.time() \n",
    "print(\"Training Time: \", t2-t1)\n",
    "#cpu_mem_report()\n",
    "gpu_mem_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c8791b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 11s 1ms/step\n",
      "Accuracy =  1.0 %\n",
      "Testing Time:  10.988710403442383\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the framework on the Test dataset\n",
    "t1 = time.time()\n",
    "\n",
    "_, acc = LeNet.evaluate(test_images, test_labels)\n",
    "print(\"Accuracy = \", (acc*100.0), \"%\")\n",
    "\n",
    "t2 = time.time() \n",
    "print(\"Testing Time: \", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c28a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training Loss')\n",
    "plt.plot(epochs, val_loss,'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379571f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc,'r', label='Validation acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd99878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyTestEnv",
   "language": "python",
   "name": "mytestenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
